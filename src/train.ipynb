{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "from typing import Sequence, NamedTuple, Any\n",
    "from flax.training.train_state import TrainState\n",
    "import distrax\n",
    "\n",
    "from jux.env import JuxEnv, JuxEnvBatch\n",
    "from jux.config import JuxBufferConfig, EnvConfig\n",
    "\n",
    "from models import NaiveActorCritic\n",
    "from preprocess import get_feature, batch_get_feature\n",
    "from constants import *\n",
    "from space import ObsSpace, ActionSpace\n",
    "from utils import get_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "from agent import naive_bid_agent, random_factory_agent_batched\n",
    "import models\n",
    "import ppo\n",
    "import preprocess as pp\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(models)\n",
    "reload(ppo)\n",
    "reload(pp)\n",
    "\n",
    "env_config = EnvConfig()\n",
    "buf_config = JuxBufferConfig(MAX_N_UNITS=1000)\n",
    "ppo_config = ppo.PPOConfig(\n",
    "    LR = 1e-4,\n",
    "    MAX_GRAD_NORM = 0.5,\n",
    "    N_ENVS = 4,\n",
    "    N_UPDATES = 1000,\n",
    "    N_EPISODES_PER_ENV= 16,\n",
    "    UPDATE_EPOCHS = 4,\n",
    "    NUM_MINIBATCHES = 32 ,\n",
    "\n",
    "    GAMMA = 0.99,\n",
    "    GAE_LAMBDA = 0.96,\n",
    "    CLIP_EPS = 0.2,\n",
    "    ENT_COEF = 0.01,  # Entropy loss coefficient\n",
    "    VF_COEF = 0.5,  # Critic loss coefficient\n",
    ")\n",
    "\n",
    "rng = jax.random.PRNGKey(seed)\n",
    "rng, _rng = jax.random.split(rng)\n",
    "\n",
    "batch_env = JuxEnvBatch(env_config, buf_config)\n",
    "num_envs = ppo_config.N_ENVS\n",
    "\n",
    "# Initialize network\n",
    "rng, _rng = jax.random.split(rng)\n",
    "\n",
    "dummy_seeds = get_seeds(_rng, (1,))\n",
    "dummy_state = batch_env.reset(dummy_seeds)\n",
    "feature = pp.batch_get_feature(dummy_state)\n",
    "network = models.NaiveActorCritic(\n",
    "    env_config=env_config,\n",
    "    buf_config=buf_config,\n",
    ")\n",
    "network_params = network.init(_rng, feature)\n",
    "\n",
    "# Optimizer - clip_by_global_norm / adam\n",
    "tx = optax.chain(\n",
    "    optax.clip_by_global_norm(ppo_config.MAX_GRAD_NORM),\n",
    "    optax.adam(ppo_config.LR, eps=1e-5),\n",
    ")\n",
    "\n",
    "train_state = TrainState.create(\n",
    "    apply_fn=network.apply,\n",
    "    params=network_params,\n",
    "    tx=tx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120385"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax.tree_util import tree_map, tree_reduce\n",
    "tree_reduce(int.__add__, tree_map(lambda x: x.size, network_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, _rng = jax.random.split(rng)\n",
    "update_state = ppo.UpdateState(train_state, _rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATE_STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize env_state\n",
    "rng, _rng = jax.random.split(rng)\n",
    "seeds = get_seeds(_rng, (num_envs,))\n",
    "env_state = batch_env.reset(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidding step\n",
    "rng, _rng = jax.random.split(rng)\n",
    "_rng = jax.random.split(_rng, num=num_envs)\n",
    "bid, faction = jax.vmap(naive_bid_agent)(env_state, _rng)\n",
    "env_state, _ = batch_env.step_bid(env_state, bid, faction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factory placement step\n",
    "n_factories = env_state.board.factories_per_team[0].astype(jnp.int32)\n",
    "\n",
    "def _factory_placement_step(i, env_state_rng):\n",
    "    env_state, rng = env_state_rng\n",
    "    rng, _rng = jax.random.split(rng)\n",
    "    _rng = jax.random.split(_rng, num=num_envs)\n",
    "    factory_placement = jax.vmap(random_factory_agent)(env_state, _rng)\n",
    "    env_state, _ = batch_env.step_factory_placement(env_state, *factory_placement)\n",
    "    return env_state, rng\n",
    "\n",
    "rng, _rng = jax.random.split(rng)\n",
    "env_state = jax.lax.fori_loop(0, n_factories, _factory_placement_step, (env_state, rng))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
